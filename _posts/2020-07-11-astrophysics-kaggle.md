---
layout: post
title: Astrophysics Kaggle Competition
featured-img: bryan-goff-_itkYVtDh8w-unsplash
mathjax: true
---
This model was created for the kaggle competition based on the Vera C. Rubin Observatory data, previously known as the Large Synoptic Survey Telescope. 

## New Challenges Caused by Big Data

The construction of this telescope necessitated the invention of new models due to the size of data that will be generated, discovering 10 to 100 times more astronomical sources that vary in the night sky than we've ever known. That's a data rate of 20--40 terabytes, or about 1 US Library of Congress, every night.
Prior to this telescope, scientists have been determining the class of any particular astrophysical source using spectroscopy.
Spectroscopy takes a tremendous amount of telescope time and there aren't enough telescopes in the world combined to keep up with the predicted event rate we are looking at.

## The Goal
Instead of using the detailed "DNA sample" that you'd get from spectroscopy, use the less detailed information in the light curves to classify astrophysical sources.
Create new techniques with the data available using photometry.

## Model
I put together my submission based on my own research as well as a combination of ideas from the kaggle competition discussions (citations throughout). It scored in the top 39%.

[Submission code.](https://github.com/Holly-E/Astrophysics-Kaggle-Competition/blob/master/Submission_code.pdf)

<https://github.com/Holly-E/Astrophysics-Kaggle-Competition>